{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3iLFeD8H192b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAhQ4zRm192e"
      },
      "outputs": [],
      "source": [
        "metadata = pd.read_csv('metadata\\\\UrbanSound8K.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HbB6wit192f"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "for i in range(len(metadata)):\n",
        "    path = 'spectrograms/' + str(metadata['classID'][i]) + '/' + str(metadata['slice_file_name'][i])[:-3] + 'png'\n",
        "    image = cv2.imread(path)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    normalized_image = gray_image / 255\n",
        "    lst.append([normalized_image , int(metadata['classID'][i])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0g2M-At192g"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "for i in range(len(lst)):\n",
        "    x.append(lst[i][0])\n",
        "    y.append(lst[i][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqALtWqP192g"
      },
      "outputs": [],
      "source": [
        "x = np.array(x).reshape(-1, 374, 500, 1)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CvJ_KpT192g"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y,  train_size = .8)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test,  train_size = .5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll34ncs5192h",
        "outputId": "2ce4409f-7d79-4d9b-801f-34e1f8548a57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X train: 6985\n",
            "y train: 6985\n",
            "X validation: 874\n",
            "y validation: 874\n",
            "X test: 873\n",
            "y test: 873\n"
          ]
        }
      ],
      "source": [
        "print(f\"X train: {len(x_train)}\")\n",
        "print(f\"y train: {len(y_train)}\")\n",
        "print(f\"X validation: {len(x_val)}\")\n",
        "print(f\"y validation: {len(y_val)}\")\n",
        "print(f\"X test: {len(x_test)}\")\n",
        "print(f\"y test: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx_rBWos192i"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv1TeB88192j"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=\"relu\", input_shape=(374, 500, 1)))\n",
        "model.add(tf.keras.layers.MaxPool2D(2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHlQUKwE192j"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(2,2))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqxl3pxl192k"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14xzVc9D192k"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsTX-8oe192l"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By4CrUmk192l"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEPsLFIe192l",
        "outputId": "0bd44c3d-2af6-475b-fcd3-7f3735da5599"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 4.87 GiB for an array with shape (6985, 374, 500, 1) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Hasnun\\Desktop\\masaaltı\\Python Projects\\GAIH\\urbansound_preprocessing.ipynb Hücre 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Hasnun/Desktop/masaalt%C4%B1/Python%20Projects/GAIH/urbansound_preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val))\n",
            "File \u001b[1;32mc:\\Users\\Hasnun\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Hasnun\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.87 GiB for an array with shape (6985, 374, 500, 1) and data type float32"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=1128, epochs=50, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXKpEQHz192m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ef546b42147b0e9f033deb3112060a229f671777683497588502bc7776901821"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}